/* ==========================================================================
   FILE: readme.txt (Project Documentation)
   ========================================================================== */
COMPUTER CODE FOR THE IMPLEMENTATION OF THE NESTED PSEUDO LIKELIHOOD (NPL) 
ESTIMATOR OF DYNAMIC PROGRAMMING DISCRETE CHOICE MODELS

This ZIP file contains computer code that implements the NPL estimator 
proposed by Aguirregabiria and Mira in the papers "Swapping the Nested 
Fixed Point Algorithm: A Class of Estimators for Discrete Markov Decision 
Models," Econometrica, 70, 1519-1543, and "Sequential Estimation of 
Dynamic Discrete Games," Econometrica, 75 (1), 1--53.
The code is written in GAUSS. 

--------------------------------------------------------------------------
SINGLE-AGENT DISCRETE-CHOICE DYNAMIC-PROGRAMMING MODELS 

FILES:

npl_sing.e	Program that estimates the bus replacement model in Rust 
		(Econometrica, 1987) using the NPL method.
This program calls the library nplprocs.lcg and the procedures 
		npl_sing.src, multilog.src , discthre.src and the 
		GAUSS dataset: bus1234.dat (bus1234.dht)

nplprocs.lcg	Gauss library

npl_sing.src	Procedure that estimates the structural parameters of a 
		discrete-choice single-agent dynamic programming model 
		using the Nested Pseudo Likelihood (NPL) algorithm in 
		Aguirregabiria and Mira (Econometrica, 2002).
It calls the procedures clogit.src.

clogit.src	Procedure for the Maximum Likelihood estimation of 
		McFadden Conditional Logit.
clogit.e 	Program that runs an example calling the procedure clogit.src.
multilog.src  	Procedure for the Maximum Likelihood estimation of 
		a Multinomial Logit.
multilog.e      Program that runs an example calling the procedure 
		multilog.src.
discthre.src	Procedure for the discretization and codification of 
		a variable using a prefixed vector of thresholds

bus1234.dat	Rust's bus replacement data set (bus engine groups 1, 2, 3 and 4)
bus1234.dht       

--------------------------------------------------------------------------------
DYNAMIC DISCRETE GAMES 

FILES:

mcarlo_psd_261207.prg	Programa that implements a Monte Carlo experiment on the 
			estimation of dynamic duopoly game of market entry-exit.
The Monte Carlo experiment considers two-step estimator,
			NPL fixed points, and NPL estimator.
The file includes all the procedures called in the program.

/* ==========================================================================
   FILE: nplprocs.lcg (Library Configuration)
   ========================================================================== */
c:\gauss8.0\myprocs\disckpie.src
    disckpie                         : proc

c:\gauss8.0\myprocs\discthre.src
    discthre                         : proc

c:\gauss8.0\myprocs\tranprob.src
    tranprob                         : proc

c:\gauss8.0\myprocs\kernel1.src
    kernel1                          : proc

c:\gauss8.0\myprocs\pctiles.src
    pctiles                          : proc

c:\gauss8.0\myprocs\multilog.src
    loglike                          : proc
    pchoice                          : proc
    multilog                         : proc

c:\gauss8.0\myprocs\npl_sing.src
    npl_sing                         : proc

c:\gauss8.0\myprocs\clogit.src
    clogit                           : proc

/* ==========================================================================
   FILE: bus1234.dht (Data Header/Schema)
   ========================================================================== */
[cite_start][cite: 159-160]
                       BUSID   MODEL   YEAR    MONTH   DREP    ACCUMILE

/* ==========================================================================
   FILE: discthre.src (Discretization Utility)
   ========================================================================== */
/*
** --------------------------------------------------------------
** DISCTHRE - Discretization and Codification of a Variable using
** a prefixed vector of thresholds.
**
** by Victor Aguirregabiria
** Last revision: September 2001
** --------------------------------------------------------------
*/
[cite_start][cite: 281-287]
proc (1) = discthre(y,thre) ;
  local numcel, discy, j ;

  numcel = rows(thre) ;
  discy = zeros(rows(y),1) ;
  discy = discy + 1*( y.<=thre[1] )  ;
  j=2 ;
  do while j<=numcel ;
    discy = discy + j*(y.>thre[j-1]).*(y.<=thre[j]) ;
    j=j+1 ;
  endo ;
  discy = discy + (numcel+1)*( y.>thre[numcel] )  ;
  retp(discy) ;
endp ;

/* ==========================================================================
   FILE: nadaraya_cv.src (Kernel Regression Procedure)
   ========================================================================== */
/*
** NADARAYA_CV.SRC
** Computes non_parametric mean of Y conditional on x using Nadaraya-Watson
** regressor and optimal window 'h' by cross-validation.
** Written by:  Victor Aguirregabiria and Gustavo Vicentini
*/
[cite_start][cite: 258-273]
proc (3) =  nadaraya_cv(xobs,yobs,xpred,hgrid,figure) ;
  local myzero, nobs, numh, cv, i, j, m_cv, kern, ky, 
        denom, hcv, mest ;
  myzero = 1e-16 ;
  nobs = rows(xobs) ;
  numh = rows(hgrid) ;
  @ ------------------- @
  @ 1. Cross-Validation @
  @ ------------------- @
  if (numh>1) ;
    cv = zeros(numh,1) ;
    i=1 ;                        
    do while i<=numh ;
      m_cv = zeros(nobs,1) ;
      j=1 ;
      do while j<=nobs ;
        kern = pdfn((xobs[j]-xobs)/hgrid[i]) ;
        ky = kern.*yobs ;
        denom = maxc((sumc(kern)-kern[j]) | myzero) ;
        m_cv[j] = (sumc(ky)-ky[j])/denom  ;
        j=j+1;
      endo;
      cv[i] = meanc((m_cv-yobs).^2) ;
      i=i+1 ;
    endo ;
    hcv = hgrid[minindc(cv)] ;
  else ;
    hcv = hgrid ;
    cv = 0 ;
  endif ;

  mest = zeros(rows(xpred),1) ;
  j=1;
  do while j<=rows(xpred) ;
    kern = pdfn((xpred[j]-xobs)/hcv) ;
    denom = maxc(sumc(kern) | myzero) ;
    mest[j] = sumc(kern.*yobs)/denom ;
    j=j+1;
  endo;
  
  if (figure==1)AND(numh>1) ;
    library pgraph ;
    graphset ;
    begwind;
      window(2,1,0);
      setwind(1);
        title("CROSS-VALIDATION FOR 'h' (GAUSSIAN KERNEL)") ;
        xlabel("Bandwidth 'h'") ;
        ylabel("CV(h)") ;
        xy(hgrid,cv) ;
      nextwind;
    title("KERNEL REGRESSION (GAUSSIAN) WITH OPTIMAL 'CV(h)' WINDOW") ;
        xlabel("X") ;
        ylabel("Y") ;
        xy(xpred,mest) ;
    endwind;
  endif ;    

retp(mest,hcv,cv) ;
endp;

/* ==========================================================================
   FILE: multilog.src (Multinomial Logit Procedure)
   ========================================================================== */
/*
** MULTILOG - Estimation of a Multinomial Logit Model by Maximum Likelihood
** Optimization algorithm: Newton's method.
** by Victor Aguirregabiria
*/
[cite_start][cite: 161-188]
proc (3) = loglike(yd,x,Fx) ;
  local myzero, nalt, kpar, llik, d1l, d2l, j, k,
        indj1, indj2, indk1, indk2 ;
  myzero = 1E-16 ;
  nalt = cols(Fx) ;
  kpar = cols(x) ;
  
  llik = 0 ;
  j=1 ;
  do while j<=nalt ;
    llik = llik + sumc((yd.==j).*ln(Fx[.,j]+myzero)) ;
    j=j+1 ;
  endo ;

  d1l = zeros(kpar*(nalt-1),1) ;
  d2l = zeros(kpar*(nalt-1),kpar*(nalt-1)) ;
  j=2 ;
  do while j<=nalt ;
    indj1 = (j-2)*kpar + 1 ;
    indj2 = (j-1)*kpar ;
    d1l[indj1:indj2] = sumc( x.*( (yd.==j) - Fx[.,j] ) ) ;
    k=2 ;
    do while k<=nalt ;
      indk1 = (k-2)*kpar + 1 ;
      indk2 = (k-1)*kpar ;
      if (j/=k) ;
        d2l[indj1:indj2,indk1:indk2] = (x.*Fx[.,j])'*(x.*Fx[.,k]) ;
      endif ;
      if (j==k) ;
        d2l[indj1:indj2,indk1:indk2] = (x.*Fx[.,j])'*(x.*Fx[.,k])
                                     - (x.*Fx[.,j])'*x ;
      endif ;
      k=k+1 ;
    endo ;
    j=j+1 ;
  endo ;
  retp(llik,d1l,d2l) ;
endp ;

proc (1) = pchoice(nalt,x,b) ;
  local xb, sumexpe, pxb ;
  b = zeros(cols(x),1) ~ ( reshape(b,nalt-1,cols(x))' ) ;
  xb = x * b ;
  xb = xb - maxc(xb') ;
  sumexpe = sumc(exp(xb')) ;
  pxb = exp(xb)./sumexpe ;
  retp(pxb) ;
endp ;

proc (2) = multilog(yobs,xobs) ;
  local nobs, nparam, kparam, nalt, eps1, eps2, namesb,
        j, matxx, b0, iter, criter1, criter2,
        Fxb0, llike, d1like, d2like, b1, Avarb, sdb, tstat,
        b0buff, sdbbuff, tbuff, k ;
  nobs = rows(yobs) ;
  kparam = cols(xobs) ;
  nalt = maxc(yobs) ;
  nparam = kparam*(nalt-1) ;
  eps1 = 1E-6 ;
  namesb = 0 $+ "b" $+ (ftocv(seqa(1,1,nalt),1,0)')
         $+ "_x" $+ ftocv(seqa(1,1,kparam),1,0) ;
  iter=1 ;
  criter1 = 1000 ;
  criter2 = 1000 ;
  b0 = zeros(kparam*(nalt-1),1) ;

  do while (criter1>eps1) ;
    Fxb0 = pchoice(nalt,xobs,b0) ;
    { llike, d1like, d2like } = loglike(yobs,xobs,Fxb0) ;
    b1 = b0 - inv(d2like)*d1like ;
    criter1 = sqrt( (b1-b0)'*(b1-b0) ) ;
    b0 = b1 ;
    iter = iter + 1 ;
  endo ;
  Fxb0 = pchoice(nalt,xobs,b0) ;
  { llike, d1like, d2like } = loglike(yobs,xobs,Fxb0) ;

  Avarb  = inv(-d2like) ;
  sdb    = sqrt(diag(Avarb)) ;
  tstat  = b0./sdb ;
  b0buff  = zeros(kparam,1) ~ ( reshape(b0,nalt-1,kparam)' ) ;
  sdbbuff = zeros(kparam,1) ~ ( reshape(sdb,nalt-1,kparam)' ) ;
  tbuff   = zeros(kparam,1) ~ ( reshape(tstat,nalt-1,kparam)' ) ;

  "" ;
  "Number of Iterations     = " iter ;
  "Log-Likelihood function  = " llike ;
  "" ;
  "-----------------------------------------------------------";
  "-----------------------------------------------------------";
  "       Parameter   Estimate    Standard    t-ratios";
  "                                Errors" ;
  "-----------------------------------------------------------";
  j=2;
  do while j<=nalt ;
    k=1 ;
    do while k<=kparam ;
      print $namesb[k,j];;b0buff[k,j];;sdbbuff[k,j];;tbuff[k,j] ;
      k=k+1 ;
    endo ;
  "-----------------------------------------------------------";
  j=j+1 ;
  endo;
  "-----------------------------------------------------------";

  retp(b0,Avarb) ;
endp ;

/* ==========================================================================
   FILE: clogit.src (Conditional Logit Procedure)
   ========================================================================== */
/*
** CLOGIT  -  Maximum Likelihood estimation of McFadden's Conditional Logit
** Optimization algorithm: Newton's method
** by Victor Aguirregabiria
*/
[cite_start][cite: 189-216]
proc (2) = clogit(ydum,x,restx,namesb) ;
  local cconvb, myzero, nobs, nalt, npar, xysum, j,
        iter, criter, llike, b0, phat, sumpx, xxm, xbuff,
        d1llike, d2llike, b1, Avarb, sdb, tstat, 
        numyj, logL0, lrindex ;
  cconvb = 1e-6 ;
  myzero = 1e-16 ;
  nobs = rows(ydum) ;
  nalt = maxc(ydum) ;
  npar = cols(x)/nalt ;
  if npar/=rows(namesb) ;
    "ERROR: Dimensions of x";; npar;; "and of names(b0)";; rows(namesb) ;;
    "do not match " ;
    end ;
  endif;

  xysum = 0 ;
  j=1;
  do while j<=nalt ;
    xysum = xysum + sumc( (ydum.==j).*x[.,npar*(j-1)+1:npar*j] ) ;
    j=j+1 ;
  endo ;

  iter=1 ;
  criter = 1000 ;
  llike = -nobs ;
  b0 = ones(npar,1) ;

  do while (criter>cconvb) ;
    "" ;
    "Iteration                = " iter ;
    "Log-Likelihood function  = " llike ;
    "Norm of b(k)-b(k-1)      = " criter ;
    "" ;
  
    @ Computing probabilities @
    phat = zeros(nobs,nalt) ;
    j=1 ;
    do while j<=nalt ;
      phat[.,j] = x[.,npar*(j-1)+1:npar*j]*b0 + restx[.,j] ;
      j=j+1 ;
    endo ;
    phat = phat - maxc(phat') ;
    phat = exp(phat)./sumc(exp(phat')) ;
    @ Computing xmean @
    sumpx = zeros(nobs,1) ;
    xxm = 0 ;
    llike = 0 ;
    j=1;
    do while j<=nalt ;
      xbuff = x[.,npar*(j-1)+1:npar*j] ; 
      sumpx = sumpx + phat[.,j] .*xbuff ;
      xxm = xxm + (phat[.,j].*xbuff)'*xbuff ;
      llike = llike
            + sumc( (ydum.==j)
                    .* ln( (phat[.,j].> myzero).*phat[.,j]
                         + (phat[.,j].<=myzero).*myzero    ) ) ;
      j=j+1 ;
    endo ;

    @ Computing gradient @
    d1llike = xysum - sumc(sumpx) ;
    @ Computing hessian @    
    d2llike = - (xxm - sumpx'*sumpx) ;
    @ Gauss iteration @
    b1 = b0 - inv(d2llike)*d1llike ;
    criter = sqrt( (b1-b0)'*(b1-b0) ) ;
    b0 = b1 ;
    iter = iter + 1 ;
  endo ;

  Avarb  = inv(-d2llike) ;
  sdb    = sqrt(diag(Avarb)) ;
  tstat  = b0./sdb ;
  
  numyj  = sumc(ydum.==(seqa(1,1,nalt)')) ;
  logL0  = sumc(numyj.*ln(numyj./nobs)) ;
  lrindex = 1 - llike/logL0 ;

  "---------------------------------------------------------------------";
  "Number of Iterations     = " iter ;
  "Number of observations   = " nobs ;
  "Log-Likelihood function  = " llike ;
  "Likelihood Ratio Index   = " lrindex ;
  "---------------------------------------------------------------------";
  "       Parameter         Estimate        Standard        t-ratios";
  "                                         Errors" ;
  "---------------------------------------------------------------------";
  j=1;
  do while j<=npar;
    print $namesb[j];;b0[j];;sdb[j];;tstat[j];
    j=j+1 ;
  endo;
  "---------------------------------------------------------------------";

  retp(b0,Avarb) ;
endp ;

/* ==========================================================================
   FILE: npl_sing.src (Core NPL Algorithm Procedure)
   ========================================================================== */
/*
** ---------------------------------------------------------------
** NPL_SING.SRC
** Maximum Likelihood Estimates of structural parameters 
** of a discrete choice single-agent dynamic programming 
** model using the NPL algorithm in 
** Aguirregabiria and Mira (Econometrica, 2002)
** ---------------------------------------------------------------
*/
[cite_start][cite: 217-247]
proc (3) = npl_sing(inda,indx,zmat,pini,bdisc,fmat,names) ;
  local npar, nobs, nchoice, myzero, eulerc, numx, 
        convcrit, convcons, tetaest0, tetaest1, varest, 
        ks, sumpz, sumpe, i_fu, j, 
        wz, we, ztilda, etilda, zobs, eobs,
        teta0, var0 , flagc ;
  npar = rows(names) ;
  nobs = rows(inda) ;
  nchoice = maxc(inda) ;
  if cols(zmat)/=(npar*nchoice) ;
    "Error: The number of columns in 'zmat' does not agree" ;
    "with the number of 'choices * number of parameters'" ;
    end ;
  endif ;
    
  myzero = 1e-12 ;
  eulerc = 0.5772 ;
  numx = rows(pini) ;
  convcrit = 1000 ;
  convcons = 1e-6 ;
  tetaest0 = zeros(npar,1) ;
  "" ;
  "     ---------------------------------------------------------" ;
  "             ESTIMATION OF STRUCTURAL PARAMETERS" ;
  "     ---------------------------------------------------------" ;
  "" ;
  ks=1 ;
  do while (convcrit>=convcons) ;
    "" ;
    " -----------------------------------------------------" ;
    " POLICY ITERATION ESTIMATOR: STAGE =" ;; ks ;
    " -----------------------------------------------------" ;
    "" ;
    @ ---------------------------------------------------------- @
    @ 1. Obtaining matrices "A=(I-beta*Fu)" and "Bz=sumj{Pj*Zj}" @
    @    and vector Be=sumj{Pj*ej}                               @
    @ ---------------------------------------------------------- @
    i_fu = zeros(numx,numx) ;
    sumpz = zeros(numx,npar) ;
    sumpe = zeros(numx,1) ;  
    j=1 ;
    do while j<=nchoice ;
      i_fu = i_fu + pini[.,j].*fmat[.,numx*(j-1)+1:numx*j] ;
      sumpz = sumpz + pini[.,j].*zmat[.,npar*(j-1)+1:npar*j] ;
      sumpe = sumpe + pini[.,j].*(eulerc - ln(pini[.,j])) ;
      j=j+1 ;
    endo ;
    i_fu = eye(numx) - bdisc * i_fu ;
    
    @ ----------------------------------------------------------@
    @ 2. Solving the linear systems "A*Wz = Bz" and "A*We = Be" @
    @    using CROUT decomposition                              @
    @ ----------------------------------------------------------@
    i_fu = crout(i_fu) ;
    wz = qrtsol(sumpz~sumpe,lowmat(i_fu)) ;
    wz = qrsol(wz,upmat1(i_fu)) ;
    clear i_fu, sumpz, sumpe ;
    we = wz[.,npar+1] ;
    wz = wz[.,1:npar] ;
      
    @ --------------------------------------------------------@
    @ 3. Computing "ztilda(a,x) = z(a,x) + beta * F(a,x)'*Wz" @
    @    and "etilda(a,x) = beta * F(a,x)'*We"                @
    @ ------------------------------------------------------- @
    ztilda = zeros(numx,nchoice*npar) ;
    etilda = zeros(numx,nchoice) ;
    j=1 ;
    do while j<=nchoice ;
      ztilda[.,npar*(j-1)+1:npar*j] = zmat[.,npar*(j-1)+1:npar*j] 
                  + bdisc * fmat[.,numx*(j-1)+1:numx*j]*wz ;
      etilda[.,j] = bdisc * fmat[.,numx*(j-1)+1:numx*j]*we ;      
      j=j+1 ;
    endo ;
    clear wz, we ;
    @ ----------------------------------------------- @
    @ 4. Sample observations of "ztilda" and "etilda" @
    @ ----------------------------------------------- @
    zobs = ztilda[indx,.] ;
    eobs = etilda[indx,.] ;

    @ ----------------------------------------@
    @ 5. Pseudo Maximum Likelihood Estimation @
    @ ----------------------------------------@
    {tetaest1 , varest} = clogit(inda,zobs,eobs,names) ;
    @ ----------------------------- @
    @ 6. Re-Computing probabilities @
    @ ----------------------------- @
    pini = zeros(numx,nchoice) ;
    j=1 ;
    do while j<=nchoice ;
      pini[.,j] = ztilda[.,npar*(j-1)+1:npar*j]*tetaest1 + etilda[.,j] ;
      j=j+1 ;
    endo ;
    pini = pini - maxc(pini') ;
    pini = exp(pini)./sumc(exp(pini')) ;
    @ -------------------------@
    @ 7. Convergence Criterion @
    @ -------------------------@
    convcrit = maxc(abs(tetaest1-tetaest0)) ;
    tetaest0 = tetaest1 ;
    "NPL Criterion =";; convcrit ;

    ks=ks+1 ;
  endo ;

  retp(tetaest1,varest,pini) ;
endp ;

/* ==========================================================================
   FILE: npl_sing.e (Main Execution Script for Single-Agent Bus Model)
   ========================================================================== */
/*
** NPL_SING_E                                                         
** This program estimates John Rust's bus engine replacement model    
** (Rust, Econometrica 1987) using the Nested Pseudo Likelihood (NPL) 
** algorithm in Aguirregabiria and Mira (Econometrica, 2002).
*/
[cite_start][cite: 288-317]
new ;
closeall ;
library nplprocs pgraph gauss ;
format /mb1 /ros 16,4 ;

/*********************/ 
/* 0. Some constants */ 
/*********************/ 
@ Names of structural parameters @
namespar = "ReplaceC" |
           "MaintenC" ;
@ Value of discount factor @               
beta = 0.99 ;
@ Number of state variables @
kvarx = 1 ;
@ Number of choice alternatives @
jchoice = 2 ;
@ Number of cells in discretization of the state variable @
ncelx = 201 ;
@ Number of observations @
nobs = 8260 ;   
@ Number of individuals (bus engines) in the data @
nindiv = 104 ;
@ Datafile @
filedat  = "c:\\MYPAPERS\\KPIE\\bus1234.dat" ;  

"" ;
"/******************************/" ; 
"/* 1. Reading Rust's bus data */" ;
"/******************************/" ; 
open dtin = ^filedat for read varindxi ;
data = readr(dtin,nobs);

iobs = data[.,ibusid] ;
@ individuals (buses) ID's @
aobs = data[.,idrep] ;      @ Replacement decision @
xobs = data[.,iaccumile] ;
@ Cumulative mileage @
xobs = xobs/1e6 ;

"" ;
"/********************************************************/" ;
"/* 2. Discretization of the decision and state variable */" ;
"/********************************************************/" ;
aval = (0|1) ;
indobsa = aobs+1 ; @ indaobs should be 1,2,...,J @

minx = quantile(xobs,0.01) ;
maxx = quantile(xobs,0.99) ;
stepx = int(1e6*(maxx-minx)/(ncelx-1) )/1e6 ;
xthre = seqa(minx+stepx,stepx,ncelx-1) ;
xval = seqa(minx,stepx,ncelx) ;
indobsx = discthre(xobs,xthre) ;

"" ;
"/****************************************/" ;
"/* 3. Specification of utility function */" ;
"/****************************************/" ;
zmat1 = zeros(ncelx,1) ~ (-xval[.,1]) ;
zmat2 = (-ones(ncelx,1)) ~ zeros(ncelx,1) ;
zmat = zmat1 ~ zmat2 ;
clear zmat1, zmat2 ;

"" ;
"/****************************************************************/" ;
"/* 4. Estimation of transition probabilities of state variables */" ;
"/****************************************************************/" ;
@ Nonparametric PDF of additional mileage @
iobs_1 = (0|iobs[1:nobs-1]) ;
xobs_1 = (0|xobs[1:nobs-1]) ;
aobs_1 = (0|aobs[1:nobs-1]) ;
dxobs = (1-aobs_1).*(xobs-xobs_1) + aobs_1.*xobs ;
dxobs = selif(dxobs,(iobs.==iobs_1)) ;
mindx = 0 ;
maxdx = quantile(dxobs,0.999) ;
numdx = 2 + int(maxdx/stepx) ;
dxval = seqa(0,stepx,numdx) ;
pdfdx = kernel1(dxobs,dxval) ;
pdfdx = pdfdx./sumc(pdfdx) ;
@ Transition matrices @
fmat2 = ones(ncelx,1).*.((pdfdx')~zeros(1,ncelx-numdx)) ;
fmat1 = (pdfdx')~zeros(1,ncelx-numdx) ;
j=2 ;
do while j<=(ncelx-1) ;
  colz = ncelx - (j-1+numdx) ;
  if (colz>0) ;
    fmat1 = fmat1 | (zeros(1,(j-1))~(pdfdx')~zeros(1,colz)) ;
  elseif (colz==0) ;
    fmat1 = fmat1 | (zeros(1,(j-1))~(pdfdx')) ;
  elseif (colz<0) ;
    buff = pdfdx[1:numdx+colz-1] | sumc(pdfdx[numdx+colz:numdx]) ;
    fmat1 = fmat1 |
            (zeros(1,(j-1))~(buff')) ;
  endif ;
  j=j+1 ;
endo ;
fmat1 = fmat1 | (zeros(1,ncelx-1)~1) ;

"" ;
"/***********************************/" ;
"/* 5. Initial choice probabilities */" ;
"/***********************************/" ;
xprob0 = ones(ncelx,1)
        ~xval[.,1]
        ~(xval[.,1].*xval[.,1])
        ~(xval[.,1].*xval[.,1].*xval[.,1]) ;
{best,varest} = multilog(indobsa,xprob0[indobsx,.]) ;
best = reshape(best,jchoice-1,cols(xprob0))' ;
prob0 = 1./(1+exp(-xprob0 * best)) ;
prob0 = (1-prob0)~prob0 ;

"" ;
"/***************************/" ;
"/* 6. Sructural estimation */" ;
"/***************************/";
{tetaest,varest,pest} =
npl_sing(indobsa,indobsx,zmat,prob0,beta,fmat1~fmat2,namespar);

end ;

/* ==========================================================================
   FILE: mcarlo_psd_261207.prg (Dynamic Games Monte Carlo Experiment)
   ========================================================================== */
/* mcarlo_psd_1207.prg                                 */
/* This programs replicates the Monte Carlo experiment */
/* in the paper by Pesendorfer and Schmidt-Dengler     */
/* (REStud, 2008)                                      */
[cite_start][cite: 15-158]
new ;
closeall ;
library pgraph ;

@ -------------- @
@  OUTPUT FILE   @
@ -------------- @  
wdir = "c:\\mypapers\\psd_mcarlo\\progau\\" ;
buff = changedir(wdir) ;
fileout  = "mcarlo_psd_1207.out" ;
output file = ^fileout reset ;
format /mb1 /ros 16,4 ;
@ -------------- @
@   PARAMETERS   @
@ -------------- @  
xv      = 0.1 ;
@ Exit value @
ce      = -0.2 ;
@ Entry cost @
pi1     = 1.2 ;
@ Monopoly  profit @
pi2     = -1.2 ;
@ Duopoly profit @
dfact   = 0.90 ;      @ Discount factor @
sigma   = 1 ;         @ Std. Dev. of eps(1)-eps(0) @

kparam  = 3 ;       @ Number of parameters to estimate @
nobs    = 10000 ;
@ Number of observations @
nrepli  = 1000 ;    @ Number of Monte Carlo replications @
npliter = 30 ;
@ Maximum number of NPL iterations @

@ vector of states is (s1,s2) @
vstate = (0~0) | (0~1) | (1~0) |
         (1~1) ;
nplayer = 2 ;
nstate = rows(vstate) ;
@ Equilibrium probabilities @
peq1 = (0.2674|0.3865|0.1998|0.2485) 
     ~ (0.7243|0.5795|0.7772|0.7062) ;
peq1 = 1-peq1 ;
peq2 = (0.38|0.69|0.17|0.39) 
     ~ (0.47|0.16|0.70|0.42) ;
peq2 = 1-peq2 ;
peq3 = (0.42|0.70|0.16|0.41) 
     ~ (0.42|0.16|0.70|0.41) ;
peq3 = 1-peq3 ;
@ ------------------------------------------------ @
@ **************** PROCEDURES    ************** @
@ ------------------------------------------------ @  

@ ---------------------------------- @
@ A. PROCEDURE EQUILIBRIUM MAPPING   @
@ ---------------------------------- @  
proc (1) = equilmap(prob0);
  local ns, newprob,
        profit1_a0, profit1_a1, profit2_a0, profit2_a1,
        iptran1_a0, iptran1_a1, iptran2_a0, iptran2_a1,
        eprofit1, eprofit2, ftran, value1, value2,
        vtilda1, vtilda2 ;
  ns = rows(prob0) ;
  newprob = prob0 ;
  @ ------------------------------ @
  @ a. Vectors of expected profits @
  @ ------------------------------ @
  profit1_a0 = xv.*vstate[.,1] ;
  profit1_a1 = ce.*(1-vstate[.,1]) 
             + pi1.*(1-prob0[.,2])
             + pi2.*prob0[.,2] ;
  eprofit1 = (1-prob0[.,1]).*profit1_a0 + prob0[.,1].*profit1_a1 
           +  sigma*pdfn(cdfni(prob0[.,1])) ;
  profit2_a0 = xv.*vstate[.,2] ;
  profit2_a1 = ce.*(1-vstate[.,2]) 
             + pi1.*(1-prob0[.,1])
             + pi2.*prob0[.,1] ;
  eprofit2 = (1-prob0[.,2]).*profit2_a0 + prob0[.,2].*profit2_a1
           +  sigma*pdfn(cdfni(prob0[.,2])) ;
  @ --------------------------- @
  @ b. Transition probabilities @
  @ --------------------------- @
  @ Remember: vstate = (0~0) | (0~1) | (1~0) | (1~1) @
  iptran1_a0 = (1-prob0[.,2]) ~ prob0[.,2]  ~ zeros(ns,1)~ zeros(ns,1) ;
  iptran1_a1 = zeros(ns,1)    ~ zeros(ns,1) ~ (1-prob0[.,2]) ~ prob0[.,2] ;
  iptran2_a0 = (1-prob0[.,1]) ~ zeros(ns,1)    ~ prob0[.,1] ~ zeros(ns,1) ;
  iptran2_a1 = zeros(ns,1)    ~ (1-prob0[.,1]) ~ zeros(ns,1)~ prob0[.,1] ;

  @ ---------------------------- @
  @ c. Updating probabilities    @
  @ ---------------------------- @
  ftran = (1-prob0[.,1]).*(1-prob0[.,2]) 
        ~ (1-prob0[.,1]).*prob0[.,2]
        ~ prob0[.,1].*(1-prob0[.,2])
        ~ prob0[.,1].*prob0[.,2] ;
  ftran = inv(eye(ns)-dfact*ftran) ;
  value1 = ftran * eprofit1 ;
  value2 = ftran * eprofit2 ;
  vtilda1 = (profit1_a1 + dfact * iptran1_a1 * value1) 
          - (profit1_a0 + dfact * iptran1_a0 * value1) ;
  vtilda2 = (profit2_a1 + dfact * iptran2_a1 * value2)
          - (profit2_a0 + dfact * iptran2_a0 * value2) ;
  newprob = cdfn(vtilda1/sigma) ~ cdfn(vtilda2/sigma) ;
  retp(newprob) ;
endp ;
@ ------------------------------- @
@ B. PROCEDURE TO SIMULATE DATA   @
@ ------------------------------- @  
proc (2) = simdygam(numobs,pchoice,pste,vecs) ;
  local seed, nums, nplayer, pbuff0, pbuff1, uobs, aobs_1, aobs ;
  nums = rows(vecs) ;
  nplayer = cols(pchoice) ;
  pbuff1 = cumsumc(pste) ;
  pbuff0 = cumsumc((0|pste[1:nums-1])) ;
  uobs = rndu(numobs,1) ;
  uobs = ((uobs.>=(pbuff0')).*(uobs.<=(pbuff1'))) * seqa(1,1,nums) ;
  aobs_1 = vecs[uobs,.] ;
  aobs = (rndu(numobs,nplayer).<=pchoice[uobs,.]) ;
  retp(aobs,aobs_1) ;
endp ;
@ -------------------------------------- @
@ C. PROCEDURE for FREQUENCY ESTIMATOR   @
@ -------------------------------------- @  
proc (1) = freqprob(yobs,xobs,xval) ;
  local numx, numq, prob1, t, selx, denom, numer ; 
  numx = rows(xval) ;
  numq = cols(yobs) ;
  prob1 = zeros(numx,numq) ;
  t=1 ;
  do while t<=numx ;
    selx = prodc((xobs.==xval[t,.])') ;
    denom = sumc(selx) ;
    if (denom==0) ;
      prob1[t,.] = zeros(1,numq) ;
    else ;
      numer = sumc(selx.*yobs) ;
      prob1[t,.] = (numer')./denom ;
    endif ;
    t=t+1 ;
  endo ;
  retp(prob1) ;
endp ;

@ --------------------------------------------- @
@ D. PRECEDURE for CONSTRINED PROBIT ESTIMATOR  @
@ --------------------------------------------- @  
proc (3) = miprobit(ydum,x,rest,b0,out) ;
  local myzero, nobs, nparam, eps, namesb, iter, llike,
        criter, Fxb0, phixb0, lamdab0, dlogLb0,
        d2logLb0, b1, lamda0, lamda1, Avarb, sdb, tstat,
        numy1, numy0, logL0, LRI, pseudoR2, k ;
  myzero = 1e-36 ;
  nobs = rows(ydum) ;
  nparam = cols(x) ;
  eps = 1E-6 ;
  namesb = seqa(1,1,nparam) ;
  namesb = 0 $+ "b" $+ ftocv(namesb,2,0);
  iter=1 ;
  llike = 1000 ;
  criter = 1000 ;
  do while (criter>eps) ;
    if (out==1) ;
      "" ;
      "Iteration                = " iter ;
      "Log-Likelihood function  = " llike ;
      "Criterion                = " criter ;
      "" ;
    endif ;
    Fxb0 = cdfn(x*b0+rest) ;
    Fxb0 = Fxb0 + (myzero - Fxb0).*(Fxb0.<myzero)
                + (1-myzero - Fxb0).*(Fxb0.>1-myzero);
    llike = ydum'*ln(Fxb0) + (1-ydum)'*ln(1-Fxb0) ;
    phixb0 = pdfn(x*b0+rest) ;
    lamdab0 = ydum.*(phixb0./Fxb0) + (1-ydum).*(-phixb0./(1-Fxb0)) ;
    dlogLb0 = x'*lamdab0 ;
    d2logLb0 = -((lamdab0.*(lamdab0 + x*b0 + rest)).*x)'*x ;
    b1 = b0 - inv(d2logLb0)*dlogLb0 ;
    criter = maxc(abs(b1-b0)) ;
    b0 = b1 ;
    iter = iter + 1 ;
  endo ;
  Fxb0 = cdfn(x*b0 + rest) ;
  Fxb0 = Fxb0 + (myzero - Fxb0).*(Fxb0.<myzero)
              + (1-myzero - Fxb0).*(Fxb0.>1-myzero);
  llike = ydum'*ln(Fxb0) + (1-ydum)'*ln(1-Fxb0) ;
  phixb0 = pdfn(x*b0 + rest) ;
  lamda0 = -phixb0./(1-Fxb0) ;
  lamda1 =  phixb0./Fxb0 ;
  Avarb  = ((lamda0.*lamda1).*x)'*x ;
  Avarb  = inv(-Avarb) ;
  sdb    = sqrt(diag(Avarb)) ;
  tstat  = b0./sdb ;
  numy1  = sumc(ydum) ;
  numy0  = nobs - numy1 ;
  logL0  = numy1*ln(numy1) + numy0*ln(numy0) - nobs*ln(nobs) ;
  LRI    = 1 - llike/logL0 ;
  pseudoR2 = 1 - ( (ydum - Fxb0)'*(ydum - Fxb0) )/numy1 ;
  if (out==1) ;
    "Number of Iterations     = " iter ;
    "Log-Likelihood function  = " llike ;
    "Likelihood Ratio Index   = " LRI ;
    "Pseudo-R2                = " pseudoR2 ;
    "" ;
    "------------------------------------------------------------------";
    "       Parameter     Estimate        Standard        t-ratios";
    "                                     Errors" ;
    "------------------------------------------------------------------";
    k=1;
    do while k<=nparam;
      print $namesb[k];;b0[k];;sdb[k];;tstat[k];
      k=k+1 ;
    endo;
    "------------------------------------------------------------------";
  endif ;
  retp(b0,Avarb,llike) ;
endp ;
@ ------------------------------- @
@ E. PROCEDURE for NPL ITERATIONS @
@ ------------------------------- @  
proc (3) = npldygam(yobs,yobs_1,pchoice,disfact,mstate,b0,kiter);
  local myzero, nobs, nplayer, numx, kparam, best, varb,
        iter, indobs, u0, u1, e0, e1, ptran, inv_bf, 
        iptran1_a0, iptran1_a1, iptran2_a0, iptran2_a1,
        umat1_a0, umat1_a1, umat2_a0, umat2_a1,
        zmat1, zmat2, emat1_a0, emat1_a1, emat2_a0, emat2_a1,
        emat1, emat2, zobs, eobs, tetaest, varest, likelihood ;
  @ ---------------@
  @ Some constants @
  @ ---------------@                
  myzero = 1e-16 ;
  nobs = rows(yobs) ;
  nplayer = cols(yobs) ;
  numx = rows(pchoice) ;
  kparam = 3 ;
  best = zeros(kparam,kiter) ;
  varb = zeros(kparam,kparam*kiter) ; 
  yobs = yobs[.,1] | yobs[.,2] ;
  @ --------------------------------------------@  
  @ Vector with indexes for the observed state  @
  @ --------------------------------------------@ 
  indobs = 1.*prodc((yobs_1.==mstate[1,.])')
         + 2.*prodc((yobs_1.==mstate[2,.])')
         + 3.*prodc((yobs_1.==mstate[3,.])')
         + 4.*prodc((yobs_1.==mstate[4,.])') ;
  @ ------------- @
  @ NPL algorithm @
  @ ------------- @ 
  iter=1 ;
  do while iter<=kiter ;
    @ ---------------------------------------- @
    @ a. Truncation of probabilities to avoid  @ 
    @    inverse Mill's ratio = +INF           @
    @ ---------------------------------------- @    
    pchoice[.,1] = (pchoice[.,1].<myzero).*myzero 
                 + (pchoice[.,1].>(1-myzero)).*(1-myzero) 
                 + (pchoice[.,1].>=myzero).*(pchoice[.,1].<=(1-myzero)).*pchoice[.,1] ;
    pchoice[.,2] = (pchoice[.,2].<myzero).*myzero 
                 + (pchoice[.,2].>(1-myzero)).*(1-myzero) 
                 + (pchoice[.,2].>=myzero).*(pchoice[.,2].<=(1-myzero)).*pchoice[.,2] ;
    @ ------------------------------------- @
    @ b. Matrix of transition probabilities @
    @ ------------------------------------- @    
    ptran = (1-pchoice[.,1]).*(1-pchoice[.,2]) 
          ~ (1-pchoice[.,1]).*pchoice[.,2]
          ~ pchoice[.,1].*(1-pchoice[.,2])
          ~ pchoice[.,1].*pchoice[.,2] ;
    @ --------------------@
    @ c. Inverse of I-b*F @
    @ --------------------@    
    inv_bf = inv(eye(numx)-disfact*ptran) ;
    @ ------------------------------------ @
    @ d. Matrices Pr(a[t] | a[t-1], ai[t]) @
    @ ------------------------------------ @
    iptran1_a0 = (1-pchoice[.,2]) ~ pchoice[.,2]   ~ zeros(nstate,1)  ~ zeros(nstate,1) ;
    iptran1_a1 = zeros(nstate,1)  ~ zeros(nstate,1)~ (1-pchoice[.,2]) ~ pchoice[.,2] ;
    iptran2_a0 = (1-pchoice[.,1]) ~ zeros(nstate,1)  ~ pchoice[.,1]    ~ zeros(nstate,1) ;
    iptran2_a1 = zeros(nstate,1)  ~ (1-pchoice[.,1]) ~ zeros(nstate,1) ~ pchoice[.,1] ;
    
    @ -----------------------------------------@
    @ e. Construction of explanatory variables @
    @ -----------------------------------------@       
    umat1_a0 = zeros(numx,kparam) ;
    umat1_a1 = (1-mstate[.,1])~(1-pchoice[.,2])~pchoice[.,2] ;
    umat2_a0 = zeros(numx,kparam) ;
    umat2_a1 = (1-mstate[.,2])~(1-pchoice[.,1])~pchoice[.,1] ;
    
    zmat1 = (1-pchoice[.,1]).*umat1_a0 + pchoice[.,1].*umat1_a1 ;
    zmat1 = inv_bf * zmat1 ;
    zmat1 = (umat1_a1 + disfact * iptran1_a1 * zmat1)
          - (umat1_a0 + disfact * iptran1_a0 * zmat1) ;
    zmat2 = (1-pchoice[.,2]).*umat2_a0 + pchoice[.,2].*umat2_a1 ;
    zmat2 = inv_bf * zmat2 ;
    zmat2 = (umat2_a1 + disfact * iptran2_a1 * zmat2)
          - (umat2_a0 + disfact * iptran2_a0 * zmat2) ;
    emat1_a0 = xv*mstate[.,1] + 0.5* pdfn(cdfni(pchoice[.,1]))./(1-pchoice[.,1]) ;
    emat1_a1 = 0.5* pdfn(cdfni(pchoice[.,1]))./pchoice[.,1] ;    
    emat2_a0 = xv*mstate[.,2] + 0.5* pdfn(cdfni(pchoice[.,2]))./(1-pchoice[.,2]) ;
    emat2_a1 = 0.5* pdfn(cdfni(pchoice[.,2]))./pchoice[.,2] ;
    
    emat1 = (1-pchoice[.,1]).*emat1_a0 + pchoice[.,1].*emat1_a1 ;
    emat1 = inv_bf * emat1 ;
    emat1 = (disfact * iptran1_a1 * emat1)
          - (xv*mstate[.,1] + disfact * iptran1_a0 * emat1) ;
    emat2 = (1-pchoice[.,2]).*emat2_a0 + pchoice[.,2].*emat2_a1 ;
    emat2 = inv_bf * emat2 ;
    emat2 = (disfact * iptran2_a1 * emat2)
          - (xv*mstate[.,2] + disfact * iptran2_a0 * emat2) ;
    zobs = zmat1[indobs,.] | zmat2[indobs,.] ;
    eobs = emat1[indobs,.] | emat2[indobs,.] ;
            
    @ ----------------------------------------@
    @ f. Pseudo Maximum Likelihood Estimation @
    @ ----------------------------------------@
    {tetaest,varest,likelihood} = miprobit(yobs,zobs,eobs,zeros(kparam,1),0) ;
    best[.,iter] = tetaest ;
    varb[.,(iter-1)*kparam+1:iter*kparam] = varest ;
                   
    @ ------------------------- @
    @ g. Updating probabilities @
    @ ------------------------- @
    pchoice[.,1] = cdfn(zmat1*tetaest +emat1) ;
    pchoice[.,2] = cdfn(zmat2*tetaest +emat2) ;
    
    iter=iter+1 ;
  endo ;
    
  retp(best,varb,likelihood) ;
endp ;
@ ------------------------------------------------ @
@ **************** MAIN PROGRAM   ************** @
@ ------------------------------------------------ @  

@ -------------------------- @
@ 1. SELECTING EQUILIBRIUM   @
@ -------------------------- @  
pequil = peq3 ;
@ ------------------------------ @
@ 2. STEADY STATE DISTRIBUTION   @
@ ------------------------------ @  
ftran = (1-pequil[.,1]).*(1-pequil[.,2]) 
      ~ (1-pequil[.,1]).*pequil[.,2]
      ~ pequil[.,1].*(1-pequil[.,2])
      ~ pequil[.,1].*pequil[.,2] ;
cconv = 1e-6 ;
criter = 1000 ;
psteady = (1/nstate)*ones(nstate,1) ;
do while criter>cconv ;
  "Criter =";; criter ;
  pbuff = ftran'*psteady ;
  criter = maxc(abs(pbuff-psteady)) ;
  psteady = pbuff ;
endo ;
@ -------------------------- @
@ 3. MONTE CARLO EXPERIMENT  @
@ -------------------------- @  
bmatfreq = zeros(kparam,nrepli*npliter) ;
bmatsim  = zeros(kparam,nrepli*npliter) ;
bmatnpl  = zeros(kparam,nrepli) ;
bmattrue = zeros(kparam,nrepli*npliter) ;
redraws=0;
draw=1 ;
do while (draw<=nrepli) ;
  "MC REPLICATION =" draw ;

  @ ---------------- @
  @ 3.1. Simulations @
  @ ---------------- @  
  flag=0 ; 
  do while (flag==0) ;
    {aobs , aobs_1} = simdygam(nobs,pequil,psteady,vstate) ;
    flag = (sumc(prodc((aobs_1.==vstate[1,.])')).>0)
         .*(sumc(prodc((aobs_1.==vstate[2,.])')).>0)
         .*(sumc(prodc((aobs_1.==vstate[3,.])')).>0)
         .*(sumc(prodc((aobs_1.==vstate[4,.])')).>0) ;
    redraws=redraws+flag;   @ counts the number of re-drawings @
  endo ; 

  @ ------------------------------------------------------------------- @
  @ 3.2. Estimation of initial CCPs: Frequency Asymmetric and Symmetric @
  @ ------------------------------------------------------------------- @
  prob_asy = freqprob(aobs,aobs_1,vstate) ;
  prob_sym = ones(nstate,nplayer) ;
  prob_sym[1,.] = meanc(prob_asy[1,.]').*ones(1,2) ;
  prob_sym[4,.] = meanc(prob_asy[1,.]').*ones(1,2) ;
  prob_sym[2,1] = (prob_asy[2,1]+prob_asy[3,2])/2 ;
  prob_sym[3,2] = prob_sym[2,1] ;
  prob_sym[3,1] = (prob_asy[3,1]+prob_asy[2,2])/2 ;
  prob_sym[2,2] = prob_sym[3,1] ;

  @ ------------------- @
  @ 3.3. NPL Estimation @
  @ ------------------- @
  theta0 = zeros(kparam,1) ;

  {best1,varb,like1} = npldygam(aobs,aobs_1,prob_asy,dfact,vstate,theta0,npliter) ;
  bmatfreq[.,(draw-1)*npliter+1:draw*npliter] = best1 ;
  {best2,varb,like2} = npldygam(aobs,aobs_1,prob_sym,dfact,vstate,theta0,npliter) ;
  bmatsim[.,(draw-1)*npliter+1:draw*npliter] = best2 ;

  bmatnpl[.,draw] = (like1.>=like2).*best1[.,npliter] 
                  + (like1.<like2) .*best2[.,npliter] ;
  {best,varb,like} = npldygam(aobs,aobs_1,pequil,dfact,vstate,theta0,npliter) ;
  bmattrue[.,(draw-1)*npliter+1:draw*npliter] = best ;

  draw=draw+1 ;
endo ;
@ ----------------- @
@ 4. SAVING RESULTS @
@ ----------------- @ 
bfreq_ex3_10k = bmatfreq ;
save bfreq_ex3_10k ;
bsim_ex3_10k = bmatsim ;
save bsim_ex3_10k ;
bnpl_ex3_10k = bmatnpl ;
save bnpl_ex3_10k ;
btrue_ex3_10k = bmattrue ;
save btrue_ex3_10k ;
ec_freq = reshape(bmatfreq[1,.],nrepli,npliter) ;
p1_freq = reshape(bmatfreq[2,.],nrepli,npliter) ;
p2_freq = reshape(bmatfreq[3,.],nrepli,npliter) ;

ec_sim = reshape(bmatsim[1,.],nrepli,npliter) ;
p1_sim = reshape(bmatsim[2,.],nrepli,npliter) ;
p2_sim = reshape(bmatsim[3,.],nrepli,npliter) ;

ec_npl = bmatnpl[1,.]' ;
p1_npl = bmatnpl[2,.]' ;
p2_npl = bmatnpl[3,.]' ;

ec_true = reshape(bmattrue[1,.],nrepli,npliter) ;
p1_true = reshape(bmattrue[2,.],nrepli,npliter) ;
p2_true = reshape(bmattrue[3,.],nrepli,npliter) ;

@ -------------- @
@ 5. STATISTICS  @
@ -------------- @  
bias_ec_freq = meanc(ec_freq  - ce) ;
bias_p1_freq = meanc(p1_freq  - pi1) ;
bias_p2_freq = meanc(p2_freq  - pi2) ;

mse_ec_freq = stdc(ec_freq).^2 + bias_ec_freq.^2 ;
mse_p1_freq = stdc(p1_freq).^2 + bias_p1_freq.^2 ;
mse_p2_freq = stdc(p2_freq).^2 + bias_p2_freq.^2 ;

bias_ec_sim = meanc(ec_sim  - ce) ;
bias_p1_sim = meanc(p1_sim  - pi1) ;
bias_p2_sim = meanc(p2_sim  - pi2) ;

mse_ec_sim = stdc(ec_sim).^2 + bias_ec_sim.^2 ;
mse_p1_sim = stdc(p1_sim).^2 + bias_p1_sim.^2 ;
mse_p2_sim = stdc(p2_sim).^2 + bias_p2_sim.^2 ;

bias_ec_npl = meanc(ec_npl  - ce) ;
bias_p1_npl = meanc(p1_npl  - pi1) ;
bias_p2_npl = meanc(p2_npl  - pi2) ;

mse_ec_npl = stdc(ec_npl).^2 + bias_ec_npl.^2 ;
mse_p1_npl = stdc(p1_npl).^2 + bias_p1_npl.^2 ;
mse_p2_npl = stdc(p2_npl).^2 + bias_p2_npl.^2 ;

bias_ec_true = meanc(ec_true  - ce) ;
bias_p1_true = meanc(p1_true  - pi1) ;
bias_p2_true = meanc(p2_true  - pi2) ;

mse_ec_true = stdc(ec_true).^2 + bias_ec_true.^2 ;
mse_p1_true = stdc(p1_true).^2 + bias_p1_true.^2 ;
mse_p2_true = stdc(p2_true).^2 + bias_p2_true.^2 ;
@ ------------------- @
@ 6. TABLE and GRAPHS @
@ ------------------- @  
format /mb1 /rzs 16,3 ;
"------------------------------------------------------------------------------------------------------------------" ;
"   MONTE CARLO EXPERIMENT: EQUILIBRIUM 3 (T=10,000)" ;
"------------------------------------------------------------------------------------------------------------------" ;
"ESTIMATOR  ";;
"       Bias C     ";;
"        MSE C  ";;
"       Bias Pi1   ";;
"        MSE Pi1";;
"       Bias Pi2   ";;
"        MSE Pi2";
"------------------------------------------------------------------------------------------------------------------" ;
"1-PML(asy)";; 
bias_ec_freq[1];; mse_ec_freq[1] ;;
bias_p1_freq[1];; mse_p1_freq[1] ;; 
bias_p2_freq[1];;
mse_p2_freq[1] ;
"10-PML(asy)";; 
bias_ec_freq[10];; mse_ec_freq[10] ;;
bias_p1_freq[10];; mse_p1_freq[10] ;; 
bias_p2_freq[10];; mse_p2_freq[10] ;
"30-PML(asy)";; 
bias_ec_freq[30];; mse_ec_freq[30] ;;
bias_p1_freq[30];; mse_p1_freq[30] ;; 
bias_p2_freq[30];;
mse_p2_freq[30] ;
"------------------------------------------------------------------------------------------------------------------" ;
"1-PML(sym)";; 
bias_ec_sim[1];; mse_ec_sim[1] ;;
bias_p1_sim[1];; mse_p1_sim[1] ;; 
bias_p2_sim[1];; mse_p2_sim[1] ;
"10-PML(sym)";; 
bias_ec_sim[10];; mse_ec_sim[10] ;;
bias_p1_sim[10];;
mse_p1_sim[10] ;; 
bias_p2_sim[10];; mse_p2_sim[10] ;
"30-PML(sym)";; 
bias_ec_sim[30];; mse_ec_sim[30] ;;
bias_p1_sim[30];; mse_p1_sim[30] ;; 
bias_p2_sim[30];; mse_p2_sim[30] ;
"------------------------------------------------------------------------------------------------------------------" ;
"1-PML(tru)";; 
bias_ec_true[1];;
mse_ec_true[1] ;;
bias_p1_true[1];; mse_p1_true[1] ;; 
bias_p2_true[1];; mse_p2_true[1] ;
"10-PML(tru)";; 
bias_ec_true[10];; mse_ec_true[10] ;;
bias_p1_true[10];; mse_p1_true[10] ;; 
bias_p2_true[10];; mse_p2_true[10] ;
"30-PML(tru)";; 
bias_ec_true[30];;
mse_ec_true[30] ;;
bias_p1_true[30];; mse_p1_true[30] ;; 
bias_p2_true[30];; mse_p2_true[30] ;
"------------------------------------------------------------------------------------------------------------------" ;
"NPL(max asy/sym)";; 
bias_ec_npl ;; mse_ec_npl ;;
bias_p1_npl ;; mse_p1_npl ;;
bias_p2_npl ;; mse_p2_npl ;
"------------------------------------------------------------------------------------------------------------------" ;

output off ;

end ;

/* ==========================================================================
   FILE: multilog.e (Example for Multilog)
   ========================================================================== */
[cite_start][cite: 5-14]
new ;
closeall ;

/**************************************************/
/* Example that calls the procedure MULTILOG.SRC  */
/**************************************************/
library myprocs pgraph ;
/****************/
/* 1. Constants */
/****************/
nalt = 5 ;
nobs = 5000 ;
npar = 4 ;

meanx = ones(1,npar-1) ;
sdx = 2* rndu(1,npar-1) ;
bmat = (0.0|0.0|0.0|0.0)
     | (-1.0|1.0|2.0|3.0) 
     |
(-2.0|1.1|2.1|3.1)
     | (-3.0|1.2|2.2|3.2) 
     | (-4.0|1.3|2.3|3.3) ;
/******************/
/* 2. Simulations */
/******************/
xobs = meanx + sdx.*rndn(nobs,npar-1) ;
xobs = ones(nobs,1)~xobs ;
eps = -ln(-ln(rndu(nobs,nalt))) ;
yobs = zeros(nobs,nalt) ;
j=1 ;
do while j<=nalt ;
  yobs[.,j] = xobs * bmat[npar*(j-1)+1:npar*j] + eps[.,j] ;
  j=j+1 ;
endo ;
yobs = maxindc(yobs') ;

meanc(yobs.==seqa(1,1,nalt)');

/*****************/
/* 3. Estimation */
/*****************/
namesb = ("b0_1" | "b1_1" | "b2_1" | "b3_1")
       |
("b0_2" | "b1_2" | "b2_2" | "b3_2")
       |
("b0_3" | "b1_3" | "b2_3" | "b3_3")
       |
("b0_4" | "b1_4" | "b2_4" | "b3_4") ;

{best, varest} = multilog(yobs,xobs) ;

/* ==========================================================================
   FILE: clogit.e (Example for CLogit)
   ========================================================================== */
[cite_start][cite: 274-280]
new ;
closeall ;

/************************************************/
/* Example that calls the procedure CLOGIT.SRC  */
/************************************************/
library myprocs pgraph ;
/****************/
/* 1. Constants */
/****************/
nalt = 5 ;
nobs = 2000 ;
npar = 3 ;

meanz = ones(nalt*npar,1) ;
sdz = 2* rndu(nalt*npar,1) ;
meanr = zeros(nalt,1) ;
sdr = rndu(nalt,1) ;
bmat = (1|2|3) ;
/******************/
/* 2. Simulations */
/******************/
zobs = (meanz') + (sdz').*rndn(nobs,nalt*npar) ;
robs = (meanr') + (sdr').*rndn(nobs,nalt) ;
eps = -ln(-ln(rndu(nobs,nalt))) ;
yobs = zeros(nobs,nalt) ;
j=1 ;
do while j<=nalt ;
  yobs[.,j] = zobs[.,npar*(j-1)+1:npar*j]*bmat + robs[.,j] + eps[.,j] ;
  j=j+1 ;
endo ;
yobs = maxindc(yobs') ;
  

/*****************/
/* 3. Estimation */
/*****************/
namesb = "b1" | "b2" | "b3" ;
{best, varest} = clogit(yobs,zobs,robs,namesb) ;

/* ==========================================================================
   FILE: nadaraya_cv.e (Example for Kernel Regression)
   ========================================================================== */
[cite_start][cite: 405-413]
new ;
closeall ;

/*****************************************************/
/* Example that calls the procedure NADARAYA_CV.SRC  */
/*****************************************************/
library myprocs pgraph ;
/****************/
/* 1. Constants */
/****************/
@ Simulating data: normal @
nobs = 200 ;
meanx = 1 ;
sdx = 5 ;
a0 = 1000 ;
a1 = 0.5 ;
a2 = -1 ;
a3 = 0.1 ;
sdeps = 10 ;
seed = 4720756 ;
x = meanx + sdx*rndns(nobs,1,seed) ;

eps = sdeps*rndns(nobs,1,seed) ;
y = a0 + a1*x + a2*x.*x + a3*x.*x.*x + eps ;
@ Percentiles: values of x in which the kernel estimator is obtained @
xval = quantile(x,seqa(1,1,99)/100) ;
@ True m(x) @
mtrue = a0 + a1*xval + a2*xval.*xval + a3*xval.*xval.*xval ;

@ Kernel m(x) @
hgrid = 1.06*stdc(x)*(nobs^(-.2)) ;
hgrid = (seqa(140,1,20)/1000)*hgrid ;

{mkern,hopt,cvfun} = nadaraya_cv(x,y,xval,hgrid,1) ;

title("True and Kernel regressions") ;
xlabel("x") ;
ylabel("m(x)") ;
xy(xval,mtrue~mkern) ;
end ;